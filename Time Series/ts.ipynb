{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gzip\n",
    "from static_grader import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Time Series Data: Predict Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Time series prediction presents its own challenges which are different from machine-learning problems.  As with many other classes of problems, there are a number of common features in these predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## A note on scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "It **is** possible to score >1 on these questions. This indicates that you've beaten our reference model - we compare our model's score on a test set to your score on a test set. See how high you can go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "!aws s3 sync s3://dataincubator-course/mldata/ . --exclude '*' --include 'train.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The columns of the data correspond to the\n",
    "  - year\n",
    "  - month\n",
    "  - day\n",
    "  - hour\n",
    "  - temp\n",
    "  - dew_temp\n",
    "  - pressure\n",
    "  - wind_angle\n",
    "  - wind_speed\n",
    "  - sky_code\n",
    "  - rain_hour\n",
    "  - rain_6hour\n",
    "  - city\n",
    "\n",
    "This function will read the data from a file handle into a Pandas DataFrame.  The grader will pass you DataFrames in this same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def load_stream(stream):\n",
    "    return pd.read_csv(stream, sep=' +', engine='python',\n",
    "                         names=['year', 'month', 'day', 'hour', 'temp',\n",
    "                                'dew_temp', 'pressure', 'wind_angle', \n",
    "                                'wind_speed', 'sky_code', 'rain_hour',\n",
    "                                'rain_6hour', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "df = load_stream(gzip.open('train.txt.gz', 'rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp'] = df['temp'].replace(-9999, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The temperature is reported in tenths of a degree Celsius.  However, not all the values are valid.  Examine the data, and remove the invalid rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We will focus on using the temporal elements to predict the temperature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Per city model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "It makes sense for each city to have it's own model.  Build a \"group-by\" estimator that takes an estimator factory as an argument and builds the resulting \"group-by\" estimator on each city.  That is, `fit` should create and fit a model per city, while the `predict` method should look up the corresponding model and perform a predict on each.  An estimator factory is something that returns an estimator each time it is called.  It could be a function or a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "class GroupbyEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, column, estimator_factory):\n",
    "        # column is the value to group by; estimator_factory can be\n",
    "        # called to produce estimators\n",
    "        self.column = column\n",
    "        self.estimator = estimator_factory()\n",
    "        self.est ={}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Create an estimator and fit it with the portion in each group\n",
    "        \n",
    "        for item in X[self.column].unique():\n",
    "            X_item = X.groupby(self.column).get_group(item)\n",
    "            y_item = y.loc[X.groupby(self.column).groups[item]]\n",
    "            X_item_model = self.estimator\n",
    "            self.est[item] = X_item_model.fit(X_item, y_item)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Call the appropriate predict method for each row of X\n",
    "        for item in X[self.column].unique():\n",
    "            X_item = X[X[self.column]==item]\n",
    "            model = self.est[item]\n",
    "        return model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "For each question, build a model to predict the temperature in a given city at a given time.  You will be given a list of records, each a string in the same format as the lines in the training file.  Return a list of predicted temperatures, one for each incoming record.  (As you can imagine, the temperature values will be stripped out in the actual text records.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Month/hour model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Seasonal features are nice because they are relatively safe to extrapolate into the future. There are two ways to handle seasonality.  \n",
    "\n",
    "The simplest (and perhaps most robust) is to have a set of indicator variables. That is, make the assumption that the temperature at any given time is a function of only the month of the year and the hour of the day, and use that to predict the temperature value.\n",
    "\n",
    "**Question**: Should month be a continuous or categorical variable?  (Recall that [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) is useful to deal with categorical variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "class ColumnTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = ['month', 'hour']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        OneHotEncoder().fit(X[self.col_names])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return OneHotEncoder().fit_transform(X[self.col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "def season_factory():\n",
    "    pipe = Pipeline([\n",
    "                            ('Transformer', ColumnTransformer(['month', 'hour'])),\n",
    "                            ('Classifier' , LinearRegression())\n",
    "    ]) \n",
    "    return pipe # A single estimator or a pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_model = GroupbyEstimator('city', season_factory).fit(df, df['temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The grader will provide a DataFrame in the same format as `load_stream` provided.  All of the temperature data will be redacted.  As long as your model accepts DataFrame input, you should be able to run the grader line below as-is.  If your model is expecting a different input, you will need to write an adapter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "grader.score('ts__month_hour_model', season_model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Fourier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Since we know that temperature is roughly sinusoidal, we know that a reasonable model might be\n",
    "\n",
    "$$ y_t = y_0 \\sin\\left(2\\pi\\frac{t - t_0}{T}\\right) + \\epsilon $$\n",
    "\n",
    "where $y_0$ and $t_0$ are parameters to be learned and $T$ is the period - one year for seasonal variation, one day for daily, etc.  While this is linear in $y_0$, it is not linear in $t_0$. However, we know from Fourier analysis, that the above is\n",
    "equivalent to\n",
    "\n",
    "$$ y_t = A \\sin\\left(2\\pi\\frac{t}{T}\\right) + B \\cos\\left(2\\pi\\frac{t}{T}\\right) + \\epsilon $$\n",
    "\n",
    "which is linear in $A$ and $B$.\n",
    "\n",
    "Create a model containing sinusoidal terms on one or more time scales, and fit it to the data using a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_data_list = []\n",
    "with gzip.open('train.txt.gz', 'rb') as f:\n",
    "    for line in f:\n",
    "        item = line.decode('utf8').strip().split(' ')\n",
    "        str_list = list(filter(None, item))\n",
    "        str_new = ' '.join(str_list[0:4])\n",
    "        city = str_list[12]\n",
    "        temp = str_list[4]\n",
    "        if temp == -9999:\n",
    "            temp = None\n",
    "        l = [city,str_new,temp]\n",
    "        q2_data_list.append(l)\n",
    "\n",
    "df_q2 = pd.DataFrame(q2_data_list)\n",
    "df_q2.columns = [\"city\",'date','temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2['date'] = pd.to_datetime(df_q2['date'])\n",
    "series = pd.Series(df_q2['temp'].values,index = df_q2['date'].values)\n",
    "temps_df = pd.DataFrame()\n",
    "temps_df['city'] = df_q2['city']\n",
    "temps_df['Julian'] = series.index.to_julian_date()\n",
    "temps_df['temp'] = df_q2['temp']\n",
    "temps_df['sin(year)'] = np.sin(temps_df['Julian'] / 365.25 * 2 * np.pi)\n",
    "temps_df['cos(year)'] = np.cos(temps_df['Julian'] / 365.25 * 2 * np.pi)\n",
    "\n",
    "temps_df = temps_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "class fftestimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    def __init__(self,city):\n",
    "        self.city = city\n",
    "        self.clf = LinearRegression()\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def fit(self,temps_df):\n",
    "        city_df = pd.DataFrame()\n",
    "        city_df = temps_df.loc[temps_df['city'] == self.city]\n",
    "        sin_year = city_df['sin(year)'].values.tolist()\n",
    "        cos_year = city_df['cos(year)'].values.tolist()\n",
    "        X_train = [list(item) for item in zip(sin_year,cos_year)]\n",
    "        Y_train = city_df['temp'].values.tolist()\n",
    "        self.q2 = self.clf.fit(X_train,Y_train)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, record):\n",
    "        item = record.to_string().split()\n",
    "        date_str = ' '.join(item[0:4])\n",
    "        city = item[12]\n",
    "        df1 = pd.DataFrame([[city,date_str]])\n",
    "        df1.columns = ['city','date']\n",
    "        df1['date'] = pd.to_datetime(date_str, errors='coerce')\n",
    "        series1 = pd.Series(df1['city'].values,index = df1['date'].values)\n",
    "        df2 = pd.DataFrame()\n",
    "        df2['Julian'] = series1.index.to_julian_date()\n",
    "        df2['sin(year)'] = np.sin(df2['Julian'] / 365.25 * 2 * np.pi)\n",
    "        df2['cos(year)'] = np.cos(df2['Julian'] / 365.25 * 2 * np.pi)\n",
    "        sin_year = df2['sin(year)'].values.tolist()[0]\n",
    "        cos_year = df2['cos(year)'].values.tolist()[0]\n",
    "        value = self.q2.predict([sin_year,cos_year])[0]\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = ['bos', 'bal', 'chi', 'nyc', 'phi']\n",
    "estimator_list = []\n",
    "for city in city_list:\n",
    "    estimator = fftestimator(city)\n",
    "    estimator_list. append(estimator.fit(temps_df))\n",
    "estimator_dict = dict(zip(city_list,estimator_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = '2011 12 30 20 -11 -72 10197 220 26 4 0 0 nyc'\n",
    "city = record.split()[12]\n",
    "estimator_dict[city].predict(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_dict[city].predict(temps_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.score('ts__fourier_model', estimator_dict[city].predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# grader.score('ts__fourier_model', lambda estimator_dict: [0] * len(estimator_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "*Copyright &copy; 2021 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
